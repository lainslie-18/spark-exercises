{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2fd67c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nprocs = multiprocessing.cpu_count()\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# create spark object\n",
    "spark = (pyspark.sql.SparkSession.builder\n",
    " .master('local')\n",
    " .config('spark.jars.packages', 'mysql:mysql-connector-java:8.0.16')\n",
    " .config('spark.driver.memory', '4G')\n",
    " .config('spark.driver.cores', nprocs)\n",
    " .config('spark.sql.shuffle.partitions', nprocs)\n",
    " .appName('MySparkApplication')\n",
    " .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de6a28",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Create a jupyter notebook or python script named `spark101` for this exercise.\n",
    "\n",
    "Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- Create a dataframe with one column named `language`\n",
    "> Hint: Start with a pandas dataframe. Maybe use a dictionary?\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a725763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typescript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>swift</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language\n",
       "0      python\n",
       "1  javascript\n",
       "2        java\n",
       "3          c#\n",
       "4  typescript\n",
       "5           r\n",
       "6       swift"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of programming languages and assign to a variable\n",
    "languages = pd.DataFrame(\n",
    "    {'language':['python', 'javascript', 'java', 'c#', 'typescript', 'r', 'swift']})\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e65513a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dataframe to a spark object\n",
    "df = spark.createDataFrame(languages)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c56dd432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6197e939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape:  7  x  1\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the dataframe\n",
    "print(\"DataFrame shape: \", df.count(), \" x \", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3bc8e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|    python|\n",
      "|javascript|\n",
      "|      java|\n",
      "|        c#|\n",
      "|typescript|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the first 5 records\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3e2c7e",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Load the `mpg` dataset as a spark dataframe.\n",
    "\n",
    "a. Create 1 column of output that contains a message like the one below for each record:\n",
    "\n",
    "    The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "> Hint: You will need to concatenate values that already exist in the data with string literals\n",
    "\n",
    "b. Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "> Hint: Consider spark string methods and `when().otherwise()` chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a20572a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d06d8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|vehicle_cylinder_description             |\n",
      "+-----------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 6 cylinder engine.|\n",
      "+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "mpg.select(concat(lit('The '), mpg.year, lit(' '), mpg.manufacturer, lit(' '), mpg.model, lit(' has a '), mpg.cyl, lit(' cylinder engine.')).alias('vehicle_cylinder_description')).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa095630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "101cc3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|     trans|trans_type|\n",
      "+----------+----------+\n",
      "|  auto(l5)|      auto|\n",
      "|manual(m5)|    manual|\n",
      "|manual(m6)|    manual|\n",
      "|  auto(av)|      auto|\n",
      "|  auto(l5)|      auto|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# b. Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "mpg.select(col('trans'), when(mpg.trans.like('a%'), 'auto').otherwise('manual').alias('trans_type')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03180ee",
   "metadata": {},
   "source": [
    "## Exercise 3: \n",
    "\n",
    "Load the `tips` dataset as a spark dataframe.\n",
    "\n",
    "a. What percentage of observations are smokers?\n",
    "\n",
    "b. Create a column that contains the tip percentage\n",
    "\n",
    "c. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18fffa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = spark.createDataFrame(data(\"tips\"))\n",
    "tips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d05fd9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+\n",
      "|smoker|count| pct|\n",
      "+------+-----+----+\n",
      "|    No|  151|62.0|\n",
      "|   Yes|   93|38.0|\n",
      "+------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy('smoker').count().withColumn('pct', \n",
    "                                          round(col('count')/tips.count()*100, 0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c0b038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = tips.withColumn('tip_pct', col('tip')/col('total_bill'))\n",
    "tips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "25096429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------------------+\n",
      "|   sex|                No|                Yes|\n",
      "+------+------------------+-------------------+\n",
      "|Female|0.1569209707691836|0.18215035269941032|\n",
      "|  Male|0.1606687151291298|0.15277117520248512|\n",
      "+------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupby('sex').pivot('smoker').agg(mean('tip_pct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f7a71c",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------\n",
    "## Exercise 4:\n",
    "\n",
    "Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9cdb0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "df = data.seattle_weather()\n",
    "df = spark.createDataFrame(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f81f8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    55.0|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    51.0|    37.0| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    53.0|    45.0| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    54.0|    42.0| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|    48.0|    37.0| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the temperatures to fahrenheit\n",
    "df = df.withColumn('temp_max', round(df.temp_max * 1.8 + 32)).withColumn('temp_min', round(df.temp_min * 1.8 + 32))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33dad82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_rain=5.354166666666667)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which month has the most rain, on average?\n",
    "df.withColumn('month', month(df.date)).groupBy('month').agg(avg('precipitation').alias('avg_rain')).sort(col('avg_rain').desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0c0aabab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(year=2012, windiness=1244.7)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which year was the windiest?\n",
    "df.withColumn('year', year(df.date)).groupBy(\"year\").agg(sum(\"wind\").alias('windiness')).sort(col('windiness').desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9f975188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(weather='fog', count=38)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most frequent type of weather in January?\n",
    "df.withColumn('month', \n",
    "              month('date')).filter(col('month') == 1).groupBy('weather').count().sort(col('count').desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1110ed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|    avg_high_temp|     avg_low_temp|\n",
      "+-----------------+-----------------+\n",
      "|80.28846153846153|57.53846153846154|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "df.withColumn('month', month('date')).withColumn('year', year('date')).filter(col('year').isin('2013', '2014')).filter(col('month') == 7).filter(col('weather') == 'sun').agg(avg('temp_max').alias('avg_high_temp'), avg('temp_min').alias('avg_low_temp')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "348c40f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|round(avg(rain), 2)|\n",
      "+-------------------+\n",
      "|               0.02|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of days were rainy in q3 of 2015?\n",
    "df.filter(year('date') == 2015).filter(quarter('date') == 3).select(when(col('weather') == 'rain', 1).otherwise(0).alias('rain')).agg(round(mean('rain'), 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8952ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    55.0|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    51.0|    37.0| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    53.0|    45.0| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    54.0|    42.0| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|    48.0|    37.0| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b0dff089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|round(avg(rain), 2)|\n",
      "+----+-------------------+\n",
      "|2012|               0.48|\n",
      "|2013|               0.42|\n",
      "|2014|               0.41|\n",
      "|2015|               0.39|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "df.withColumn('year', year('date')).select(when(col('precipitation') > 0, 1).otherwise(0).alias('rain'), 'year').groupby('year').agg(round(mean('rain'), 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a1017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
